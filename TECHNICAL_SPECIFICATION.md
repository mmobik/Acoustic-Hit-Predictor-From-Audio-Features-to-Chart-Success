# ТЕХНИЧЕСКОЕ ЗАДАНИЕ
## Acoustic Hit Predictor: Прогнозирование популярности музыкальных треков

---

### 1. ОБЩИЕ ПОЛОЖЕНИЯ

#### 1.1 Цель проекта
Разработка модели машинного обучения для прогнозирования популярности акустических музыкальных треков на основе аудио-характеристик платформы Spotify.

#### 1.2 Назначение системы
Предоставление аналитического инструмента для:
- Музыкальных продюсеров при оценке потенциала треков
- Артистов при планировании творческих решений
- A&R менеджеров при отборе материала
- Исследователей музыкальной индустрии

#### 1.3 Источник данных
Датасет аудио-характеристик треков из Spotify API, включающий:
- Акустические параметры (энергия, танцевальность, темп и др.)
- Метаданные (исполнитель, жанр, длительность)
- Целевая переменная: показатель популярности (popularity score)

---

### 2. ЭТАПЫ РЕАЛИЗАЦИИ ПРОЕКТА

#### ЭТАП 1: EXPLORATORY DATA ANALYSIS (EDA)

**Задачи:**

1. **Анализ целевой переменной**
   - Построение распределения `popularity`
   - Выявление выбросов и аномалий
   - Определение диапазона значений и медианы
   - **Вывод:** Характеристика распределения таргета

2. **Исследование числовых признаков**
   - Гистограммы распределений для каждого признака
   - Box plots для выявления выбросов
   - Описательная статистика (mean, median, std, quartiles)
   - **Вывод:** Идентификация признаков с аномальными распределениями

3. **Анализ категориальных признаков**
   - Частотный анализ артистов и жанров
   - Визуализация топ-N категорий
   - Анализ влияния категорий на популярность
   - **Вывод:** Выявление наиболее популярных категорий

4. **Корреляционный анализ**
   - Построение матрицы корреляций Пирсона
   - Выделение признаков с сильной корреляцией с таргетом (|r| > 0.3)
   - Heatmap визуализация
   - **Вывод:** Ранжирование признаков по силе связи с популярностью

5. **Визуализация взаимосвязей**
   - Scatter plots для пар признаков с высокой корреляцией
   - Pairplot для ключевых признаков
   - Анализ нелинейных зависимостей
   - **Вывод:** Выявление паттернов и закономерностей

6. **Итоговые выводы по EDA**
   - Ключевые инсайты о данных
   - Гипотезы для feature engineering
   - Рекомендации по предобработке

**Инструменты:** pandas, numpy, matplotlib, seaborn, scipy.stats

**Deliverables:**
- Jupyter Notebook с полным EDA
- Визуализации в высоком разрешении
- Документированные выводы после каждого графика

---

#### ЭТАП 2: FEATURE ENGINEERING

**Задачи:**

1. **Создание производных признаков**
   
   Обязательные признаки:
   - `duration_min` = duration_ms / 60000 (длительность в минутах)
   - `energy_dance_ratio` = energy / danceability (баланс энергии и танцевальности)
   - `acoustic_energy_balance` = acousticness * (1 - energy) (акустический баланс)
   - `tempo_energy_product` = tempo * energy (темпо-энергетический индекс)
   - `valence_energy_interaction` = valence * energy (позитивность × энергия)
   
   Дополнительные признаки (экспериментальные):
   - Полиномиальные комбинации ключевых признаков
   - Логарифмические трансформации
   - Бинаризация непрерывных признаков

2. **Анализ корреляции новых признаков**
   - Расчет корреляции каждого нового признака с `popularity`
   - Сравнение с исходными признаками
   - **Вывод:** Эффективность созданных признаков

3. **Feature Importance Analysis**
   - Обучение Random Forest Regressor
   - Извлечение feature importances
   - Визуализация топ-20 признаков
   - **Вывод:** Ранжирование признаков по важности

4. **Baseline модель**
   - Построение Linear Regression на всех признаках
   - Метрики: MAE, RMSE, R²
   - **Вывод:** Базовая производительность для сравнения

**Инструменты:** scikit-learn, feature-engine

**Deliverables:**
- Функции для генерации признаков
- Отчет по корреляциям
- Baseline метрики

---

#### ЭТАП 3: MACHINE LEARNING EXPERIMENTS

**Задачи:**

1. **Линейные модели**
   - Linear Regression (базовая)
   - Ridge Regression (с регуляризацией L2)
   - Lasso Regression (с регуляризацией L1)
   - **Вывод:** Эффективность линейных зависимостей

2. **Древовидные модели**
   - Decision Tree Regressor
   - Random Forest Regressor
   - Extra Trees Regressor
   - **Вывод:** Способность к захвату нелинейностей

3. **Градиентный бустинг**
   - XGBoost Regressor
   - LightGBM Regressor
   - CatBoost Regressor
   - **Вывод:** Производительность ансамблевых методов

4. **Нейронные сети**
   - MLPRegressor (Multi-Layer Perceptron)
   - Архитектура: минимум 2 скрытых слоя
   - Активация: ReLU, оптимизатор: Adam
   - **Вывод:** Эффективность глубокого обучения

5. **Сравнительный анализ**
   - Таблица метрик для всех моделей
   - Метрики: MAE, RMSE, R², MAPE
   - Время обучения и предсказания
   - **Вывод:** Выбор лучшей модели

**Методология:**
- Train/Test split: 80/20
- Стандартизация признаков (StandardScaler)
- Фиксированный random_state для воспроизводимости

**Инструменты:** scikit-learn, xgboost, lightgbm, catboost

**Deliverables:**
- Обученные модели
- Сравнительная таблица метрик
- Визуализация результатов

---

#### ЭТАП 4: ФИНАЛЬНАЯ МОДЕЛЬ И ОПТИМИЗАЦИЯ

**Задачи:**

1. **Кросс-валидация**
   - K-Fold Cross-Validation (k ≥ 5)
   - Метрики: среднее и стандартное отклонение по фолдам
   - **Вывод:** Стабильность модели

2. **Гиперпараметрическая оптимизация**
   - Grid Search или Random Search
   - Оптимизация по метрике MAE
   - Валидация на отложенной выборке
   - **Вывод:** Оптимальные параметры

3. **Финальная оценка**
   - Обучение на полном train set с лучшими параметрами
   - Оценка на test set
   - Анализ остатков (residuals)
   - **Вывод:** Итоговая производительность модели

4. **Интерпретация модели**
   - SHAP values (для tree-based моделей)
   - Feature importance
   - Partial Dependence Plots
   - **Вывод:** Объяснение предсказаний

**Инструменты:** scikit-learn, optuna/hyperopt, shap

**Deliverables:**
- Финальная модель (сериализованная)
- Отчет по кросс-валидации
- Интерпретационные графики

---

#### ЭТАП 5: ВЫВОДЫ И ДОКУМЕНТАЦИЯ

**Задачи:**

1. **Ключевые факторы популярности**
   - Топ-10 признаков по важности
   - Направление влияния (положительное/отрицательное)
   - Количественная оценка влияния

2. **Практические рекомендации**
   - Для музыкантов: оптимальные характеристики треков
   - Для продюсеров: критерии отбора материала
   - Для маркетологов: таргетинг аудитории

3. **Ограничения исследования**
   - Качество и полнота данных
   - Ограничения выбранных моделей
   - Внешние факторы, не учтенные в модели

4. **Направления улучшения**
   - Дополнительные источники данных
   - Альтернативные подходы к моделированию
   - Возможности развертывания в продакшн

**Deliverables:**
- Финальный отчет (Markdown/PDF)
- Презентация результатов
- README с инструкциями по воспроизведению

---

### 3. КРИТЕРИИ УСПЕХА ПРОЕКТА

#### 3.1 Количественные метрики

| Метрика | Целевое значение | Критичность |
|---------|------------------|-------------|
| MAE (Mean Absolute Error) | < 15 | Обязательно |
| RMSE (Root Mean Squared Error) | < 20 | Желательно |
| R² (Coefficient of Determination) | > 0.3 | Обязательно |
| MAPE (Mean Absolute Percentage Error) | < 25% | Желательно |

#### 3.2 Качественные критерии

1. **Интерпретируемость**
   - Понятные факторы успеха
   - Объяснимые предсказания
   - Визуализация важности признаков

2. **Практическая ценность**
   - Actionable insights для музыкальной индустрии
   - Конкретные рекомендации
   - Применимость в реальных сценариях

3. **Воспроизводимость**
   - Фиксированные random seeds
   - Документированный pipeline
   - Версионирование зависимостей

---

### 4. ТЕХНИЧЕСКИЕ ТРЕБОВАНИЯ

#### 4.1 Среда разработки

**Поддерживаемые платформы:**
- Anaconda Navigator (локальная разработка)
- Google Colab (облачные вычисления)
- JupyterLab / VS Code (IDE)

#### 4.2 Формат работы
- **Основной формат:** Jupyter Notebook (.ipynb)
- **Структура:** Один notebook на этап или единый pipeline
- **Документация:** Markdown-ячейки с пояснениями

#### 4.3 Зависимости

```python
# Основные библиотеки
pandas >= 1.5.0
numpy >= 1.23.0
scikit-learn >= 1.2.0
matplotlib >= 3.6.0
seaborn >= 0.12.0

# ML фреймворки
xgboost >= 1.7.0
lightgbm >= 3.3.0
catboost >= 1.1.0

# Интерпретация
shap >= 0.41.0

# Утилиты
jupyter >= 1.0.0
ipywidgets >= 8.0.0
```

#### 4.4 Структура проекта

```
Acoustic-Hit-Predictor/
│
├── data/
│   ├── raw/                    # Исходные данные
│   ├── processed/              # Обработанные данные
│   └── features/               # Сгенерированные признаки
│
├── notebooks/
│   ├── 01_EDA.ipynb           # Exploratory Data Analysis
│   ├── 02_Feature_Engineering.ipynb
│   ├── 03_Model_Experiments.ipynb
│   ├── 04_Final_Model.ipynb
│   └── 05_Results_Analysis.ipynb
│
├── src/
│   ├── data_preprocessing.py   # Функции предобработки
│   ├── feature_engineering.py  # Генерация признаков
│   ├── models.py              # Обертки для моделей
│   └── visualization.py       # Функции визуализации
│
├── models/
│   └── final_model.pkl        # Сохраненная модель
│
├── reports/
│   ├── figures/               # Графики и визуализации
│   └── final_report.md        # Итоговый отчет
│
├── requirements.txt
├── README.md
└── TECHNICAL_SPECIFICATION.md  # Этот документ
```

---

### 5. ПЛАН ВЫПОЛНЕНИЯ

| Этап | Длительность | Deliverables |
|------|--------------|--------------|
| 1. EDA | 2-3 дня | Notebook с анализом, визуализации |
| 2. Feature Engineering | 1-2 дня | Новые признаки, baseline модель |
| 3. ML Experiments | 2-3 дня | Сравнение моделей, таблица метрик |
| 4. Финальная модель | 1-2 дня | Оптимизированная модель, CV результаты |
| 5. Документация | 1 день | Отчет, презентация, README |
| **ИТОГО** | **7-11 дней** | Полный ML pipeline |

---

### 6. КРИТЕРИИ ПРИЕМКИ

#### 6.1 Обязательные требования
- ✅ Выполнены все 5 этапов
- ✅ Достигнуты целевые метрики (MAE < 15, R² > 0.3)
- ✅ Код документирован и воспроизводим
- ✅ Результаты визуализированы
- ✅ Выводы сформулированы после каждого анализа

#### 6.2 Дополнительные требования
- ⭐ Kaggle submission (если применимо)
- ⭐ Веб-интерфейс для демонстрации
- ⭐ API для предсказаний
- ⭐ Docker-контейнер для развертывания

---

### 7. КОНТАКТЫ И РЕСУРСЫ

**Репозиторий проекта:** [GitHub Link]

**Документация Spotify API:** https://developer.spotify.com/documentation/web-api/

**Референсные исследования:**
- Music Information Retrieval (MIR) papers
- Kaggle competitions on music prediction

---

**Версия документа:** 1.0  
**Дата создания:** 2025-11-29  
**Статус:** Утверждено к реализации

---

*Данное техническое задание является руководством для разработки ML-модели прогнозирования популярности музыкальных треков. Все этапы должны быть выполнены последовательно с обязательным документированием результатов.*
